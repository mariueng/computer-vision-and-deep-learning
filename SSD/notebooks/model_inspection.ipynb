{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoimport changes in code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.dirname(os.getcwd())) # Include ../SSD in path\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from vizer.draw import draw_boxes\n",
    "from tops.config import instantiate, LazyConfig\n",
    "from ssd import utils\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mariu/dev/school/TDT4265/project/computer-vision-and-deep-learning/SSD\n"
     ]
    }
   ],
   "source": [
    "# Only necessary to run this on local machine\n",
    "# ['/data', '/dataset_exploration', '/datasets', '/demo', '']\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select run\n",
    "run = \"task2_1\"\n",
    "input_size = (3, 128, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving SSD outputs to: outputs/\n"
     ]
    }
   ],
   "source": [
    "from ssd.utils import load_config\n",
    "cfg = load_config(f\"configs/{run}.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tops.config import instantiate\n",
    "model = instantiate(cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1        [-1, 32, 128, 1024]             896\n",
      "       BatchNorm2d-2        [-1, 32, 128, 1024]              64\n",
      "         LeakyReLU-3        [-1, 32, 128, 1024]               0\n",
      "            Conv2d-4        [-1, 64, 128, 1024]          18,496\n",
      "       BatchNorm2d-5        [-1, 64, 128, 1024]             128\n",
      "         LeakyReLU-6        [-1, 64, 128, 1024]               0\n",
      "         MaxPool2d-7          [-1, 64, 64, 512]               0\n",
      "            Conv2d-8         [-1, 128, 64, 512]          73,856\n",
      "       BatchNorm2d-9         [-1, 128, 64, 512]             256\n",
      "        LeakyReLU-10         [-1, 128, 64, 512]               0\n",
      "           Conv2d-11         [-1, 128, 64, 512]         147,584\n",
      "      BatchNorm2d-12         [-1, 128, 64, 512]             256\n",
      "        LeakyReLU-13         [-1, 128, 64, 512]               0\n",
      "        MaxPool2d-14         [-1, 128, 32, 256]               0\n",
      "           Conv2d-15         [-1, 256, 32, 256]         295,168\n",
      "      BatchNorm2d-16         [-1, 256, 32, 256]             512\n",
      "        LeakyReLU-17         [-1, 256, 32, 256]               0\n",
      "           Conv2d-18         [-1, 512, 32, 256]       1,180,160\n",
      "      BatchNorm2d-19         [-1, 512, 32, 256]           1,024\n",
      "        LeakyReLU-20         [-1, 512, 32, 256]               0\n",
      "           Conv2d-21         [-1, 128, 32, 256]         589,952\n",
      "      BatchNorm2d-22         [-1, 128, 32, 256]             256\n",
      "        LeakyReLU-23         [-1, 128, 32, 256]               0\n",
      "           Conv2d-24         [-1, 512, 32, 256]         590,336\n",
      "      BatchNorm2d-25         [-1, 512, 32, 256]           1,024\n",
      "        LeakyReLU-26         [-1, 512, 32, 256]               0\n",
      "           Conv2d-27         [-1, 256, 16, 128]       1,179,904\n",
      "      BatchNorm2d-28         [-1, 256, 16, 128]             512\n",
      "        LeakyReLU-29         [-1, 256, 16, 128]               0\n",
      "           Conv2d-30         [-1, 256, 16, 128]         590,080\n",
      "      BatchNorm2d-31         [-1, 256, 16, 128]             512\n",
      "        LeakyReLU-32         [-1, 256, 16, 128]               0\n",
      "           Conv2d-33           [-1, 128, 8, 64]         295,040\n",
      "      BatchNorm2d-34           [-1, 128, 8, 64]             256\n",
      "        LeakyReLU-35           [-1, 128, 8, 64]               0\n",
      "           Conv2d-36           [-1, 128, 8, 64]         147,584\n",
      "      BatchNorm2d-37           [-1, 128, 8, 64]             256\n",
      "        LeakyReLU-38           [-1, 128, 8, 64]               0\n",
      "           Conv2d-39           [-1, 128, 4, 32]         147,584\n",
      "      BatchNorm2d-40           [-1, 128, 4, 32]             256\n",
      "        LeakyReLU-41           [-1, 128, 4, 32]               0\n",
      "           Conv2d-42           [-1, 128, 4, 32]         147,584\n",
      "      BatchNorm2d-43           [-1, 128, 4, 32]             256\n",
      "        LeakyReLU-44           [-1, 128, 4, 32]               0\n",
      "           Conv2d-45            [-1, 64, 2, 16]          73,792\n",
      "      BatchNorm2d-46            [-1, 64, 2, 16]             128\n",
      "        LeakyReLU-47            [-1, 64, 2, 16]               0\n",
      "           Conv2d-48           [-1, 128, 2, 16]          73,856\n",
      "      BatchNorm2d-49           [-1, 128, 2, 16]             256\n",
      "        LeakyReLU-50           [-1, 128, 2, 16]               0\n",
      "           Conv2d-51             [-1, 64, 1, 8]          32,832\n",
      "BasicModelExtended-52  [[-1, 128, 32, 256], [-1, 256, 16, 128], [-1, 128, 8, 64], [-1, 128, 4, 32], [-1, 64, 2, 16], [-1, 64, 1, 8]]               0\n",
      "           Conv2d-53          [-1, 16, 32, 256]          18,448\n",
      "           Conv2d-54          [-1, 36, 32, 256]          41,508\n",
      "           Conv2d-55          [-1, 24, 16, 128]          55,320\n",
      "           Conv2d-56          [-1, 54, 16, 128]         124,470\n",
      "           Conv2d-57            [-1, 24, 8, 64]          27,672\n",
      "           Conv2d-58            [-1, 54, 8, 64]          62,262\n",
      "           Conv2d-59            [-1, 24, 4, 32]          27,672\n",
      "           Conv2d-60            [-1, 54, 4, 32]          62,262\n",
      "           Conv2d-61            [-1, 16, 2, 16]           9,232\n",
      "           Conv2d-62            [-1, 36, 2, 16]          20,772\n",
      "           Conv2d-63             [-1, 16, 1, 8]           9,232\n",
      "           Conv2d-64             [-1, 36, 1, 8]          20,772\n",
      "================================================================\n",
      "Total params: 6,070,278\n",
      "Trainable params: 6,070,278\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.50\n",
      "Forward/backward pass size (MB): 800.76\n",
      "Params size (MB): 23.16\n",
      "Estimated Total Size (MB): 825.42\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, input_size=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_to_visualize = \"train\" # or \"val\"\n",
    "\n",
    "cfg.train.batch_size = 32\n",
    "\n",
    "if dataset_to_visualize == \"train\":\n",
    "    # Remove GroundTruthBoxesToAnchors transform\n",
    "    if cfg.data_train.dataset._target_ == torch.utils.data.ConcatDataset:\n",
    "        for dataset in cfg.data_train.dataset.datasets:\n",
    "            print(dataset.transform.transforms)\n",
    "            dataset.transform.transforms = dataset.transform.transforms[:-1]\n",
    "    else:\n",
    "        cfg.data_train.dataset.transform.transforms = cfg.data_train.dataset.transform.transforms[:-1]\n",
    "    dataset = instantiate(cfg.data_train.dataloader)\n",
    "    gpu_transform = instantiate(cfg.data_train.gpu_transform)\n",
    "else:\n",
    "    cfg.data_val.dataloader.collate_fn = utils.batch_collate\n",
    "    dataset = instantiate(cfg.data_val.dataloader) \n",
    "    gpu_transform = instantiate(cfg.data_val.gpu_transform)\n",
    "\n",
    "# Assumes that the first GPU transform is Normalize\n",
    "# If it fails, just change the index from 0.\n",
    "image_mean = torch.tensor(cfg.data_train.gpu_transform.transforms[0].mean).view(1, 3, 1, 1)\n",
    "image_std = torch.tensor(cfg.data_train.gpu_transform.transforms[0].std).view(1, 3, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataiter = iter(dataset)\n",
    "# sample = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter(f'runs/{run}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariu/dev/school/TDT4265/project/computer-vision-and-deep-learning/SSD/ssd/modeling/backbones/basic.py:96: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert feature.shape[1:] == expected_shape, \\\n",
      "/Users/mariu/dev/school/TDT4265/project/computer-vision-and-deep-learning/SSD/ssd/utils/box_utils.py:23: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert boxes_center.shape[-1] == 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only tensors, lists, tuples of tensors, or dictionary of tensors can be output from traced functions\n",
      "Error occurs, No graph saved\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Only tensors, lists, tuples of tensors, or dictionary of tensors can be output from traced functions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bw/xj159s751_s5rj39wj1_r2900000gn/T/ipykernel_30666/2946538609.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdummy_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tdt4265/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36madd_graph\u001b[0;34m(self, model, input_to_model, verbose, use_strict_trace)\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'forward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;31m# A valid PyTorch model should have a 'forward' method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_to_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_strict_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;31m# Caffe2 models do not have the 'forward' method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tdt4265/lib/python3.8/site-packages/torch/utils/tensorboard/_pytorch_graph.py\u001b[0m in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose, use_strict_trace)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error occurs, No graph saved'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tdt4265/lib/python3.8/site-packages/torch/utils/tensorboard/_pytorch_graph.py\u001b[0m in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose, use_strict_trace)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_model_mode_for_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainingMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# TODO: move outside of torch.onnx?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_strict_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m             \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_inline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tdt4265/lib/python3.8/site-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m         return trace_module(\n\u001b[0m\u001b[1;32m    742\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0;34m\"forward\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tdt4265/lib/python3.8/site-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    956\u001b[0m             \u001b[0mexample_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m             module._c._create_method_from_trace(\n\u001b[0m\u001b[1;32m    959\u001b[0m                 \u001b[0mmethod_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Only tensors, lists, tuples of tensors, or dictionary of tensors can be output from traced functions"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.rand(1, 3, 128, 1024)\n",
    "writer.add_graph(model, dummy_input)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.8.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b53cd25f72a00c919db9f9f43fdde15b1d5c1f2e3da36e4a0b6ae6a0568d2a5b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tdt4265')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
