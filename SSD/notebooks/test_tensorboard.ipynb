{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os\n",
    "sys.path.append(os.path.dirname(os.getcwd())) # Include ../SSD in path\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from vizer.draw import draw_boxes\n",
    "from tops.config import instantiate, LazyConfig\n",
    "from ssd import utils\n",
    "\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mariu/dev/school/TDT4265/project/computer-vision-and-deep-learning/SSD\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving SSD outputs to: outputs/\n"
     ]
    }
   ],
   "source": [
    "run = \"task2_2\"\n",
    "config_path = f\"configs/{run}.py\"\n",
    "cfg = LazyConfig.load(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_to_visualize = \"train\" # or \"val\"\n",
    "\n",
    "# THIS NEEDS TO MATCH BATCH USED WHEN TRAINING, else dataloader goes fucking crazy\n",
    "cfg.train.batch_size = 1\n",
    "\n",
    "if dataset_to_visualize == \"train\":\n",
    "    # Remove GroundTruthBoxesToAnchors transform\n",
    "    if cfg.data_train.dataset._target_ == torch.utils.data.ConcatDataset:\n",
    "        for dataset in cfg.data_train.dataset.datasets:\n",
    "            dataset.transform.transforms = dataset.transform.transforms[:-1]\n",
    "    else:\n",
    "        cfg.data_train.dataset.transform.transforms = cfg.data_train.dataset.transform.transforms[:-1]\n",
    "    dataset = instantiate(cfg.data_train.dataloader)\n",
    "    gpu_transform = instantiate(cfg.data_train.gpu_transform)\n",
    "else:\n",
    "    cfg.data_val.dataloader.collate_fn = utils.batch_collate\n",
    "    dataset = instantiate(cfg.data_val.dataloader)\n",
    "    gpu_transform = instantiate(cfg.data_val.gpu_transform)\n",
    "\n",
    "# Assumes that the first GPU transform is Normalize\n",
    "# If it fails, just change the index from 0.\n",
    "# image_mean = torch.tensor(cfg.data_train.gpu_transform.transforms[0].mean).view(1, 3, 1, 1)\n",
    "# image_std = torch.tensor(cfg.data_train.gpu_transform.transforms[0].std).view(1, 3, 1, 1)\n",
    "model = instantiate(cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(dataset))\n",
    "sample = gpu_transform(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.jit import _trace\n",
    "\n",
    "# module = _trace(model.forward(sample[\"image\"]), sample[\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 128, 1024])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Create dummy input\n",
    "dummy_input = torch.rand(1, 3, 128, 1024)\n",
    "shape = torch.Size((1, 3, 128, 1024))\n",
    "# dummy_input = torch.cuda.FloatTensor(shape)\n",
    "torch.randn(shape, out=dummy_input)\n",
    "print(dummy_input.shape)\n",
    "print(type(dummy_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = SummaryWriter(f'notebooks/runs/{run}')\n",
    "model = instantiate(cfg.model)\n",
    "\n",
    "image = sample[\"image\"]\n",
    "\n",
    "tb.add_graph(model, image)\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Pytorch SSD300 implementation\n",
    "# Might have to use: map_location=torch.device('cpu')\n",
    "ssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd')\n",
    "utils_ = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd_model.to('cuda')\n",
    "ssd_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uris = [\n",
    "    'http://images.cocodataset.org/val2017/000000397133.jpg',\n",
    "    'http://images.cocodataset.org/val2017/000000037777.jpg',\n",
    "    'http://images.cocodataset.org/val2017/000000252219.jpg'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [utils_.prepare_input(uri) for uri in uris]\n",
    "tensor = utils_.prepare_tensor(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.add_graph(ssd_model, tensor[0])\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    detections_batch = ssd_model(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_per_input = utils_.decode_results(detections_batch)\n",
    "best_results_per_input = [utils_.pick_best(results, 0.40) for results in results_per_input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_to_labels = utils_.get_coco_object_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "for image_idx in range(len(best_results_per_input)):\n",
    "    fig, ax = plt.subplots(1)\n",
    "    # Show original, denormalized image...\n",
    "    image = inputs[image_idx] / 2 + 0.5\n",
    "    ax.imshow(image)\n",
    "    # ...with detections\n",
    "    bboxes, classes, confidences = best_results_per_input[image_idx]\n",
    "    for idx in range(len(bboxes)):\n",
    "        left, bot, right, top = bboxes[idx]\n",
    "        x, y, w, h = [val * 300 for val in [left, bot, right - left, top - bot]]\n",
    "        rect = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(x, y, \"{} {:.0f}%\".format(classes_to_labels[classes[idx] - 1], confidences[idx]*100), bbox=dict(facecolor='white', alpha=0.5))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b53cd25f72a00c919db9f9f43fdde15b1d5c1f2e3da36e4a0b6ae6a0568d2a5b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('tdt4265')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
