from utils import (
    calculate_precision,
    calculate_recall,
    calculate_f_score,
    calculate_precision_recall_all_images,
    get_precision_recall_curve,
    plot_precision_recall_curve,
    calculate_mean_average_precision,
    mean_average_precision
)


"""
Bare minimum for this task is to report the following metrics for each analysis:

    * COCO mAP@0.5:0.95 (calculated in tensorboard)
    * Inference speed. This can be avluated by running the script runtime_analysis.py
    * Number of parameters (this is calculated)
    * Plots of loss(es) (also shown in tensorboard by logs)

Other metrics that could be considered are:

    * Finaly accuracy/accuracy plots
    * Average precision
    * Precision/recall plots
    * Confusion matrix (actual vs prediction)
    * ROC curve
    * Precision-recall curve
    * Classification report
    * F1 score

"""




if __name__ == "__main__":
    pass
